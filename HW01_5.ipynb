{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "signal-depth",
   "metadata": {},
   "source": [
    "# HW01 Ranked Retrieval and Document Vectorizarion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-genome",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italian-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for excecution\n",
    "from IPython.display import clear_output\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary, doc_corpus, query_corpus and df with tags\n",
    "dictionary = corpora.Dictionary.load('resources/vocab.dict')\n",
    "doc_corpus = corpora.MmCorpus(\"resources/doc_corpus.mm\")\n",
    "query_corpus = corpora.MmCorpus(\"resources/query_corpus.mm\")\n",
    "df = pd.read_csv('./data/relevance-judgments.tsv', sep='\\t', header=None)\n",
    "df.columns = ['query', 'doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-concern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(331 documents, 17365 features, 81038 non-zero entries)\n",
      "MmCorpus(35 documents, 16373 features, 110 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "# Glimpse to doc and query corpus\n",
    "print(doc_corpus)\n",
    "print(query_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "median-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28178188]\n",
      " [1.5655855 ]\n",
      " [1.519828  ]\n",
      " ...\n",
      " [2.519828  ]\n",
      " [2.519828  ]\n",
      " [2.519828  ]]\n"
     ]
    }
   ],
   "source": [
    "binary_matrix = np.load('./resources/BSmatrix.npy')\n",
    "N = len(doc_corpus)\n",
    "idf_array = np.zeros((len(dictionary),1), dtype = np.float32)\n",
    "for i in range(binary_matrix.shape[0]):\n",
    "    idf_array[i] = np.log10(N/len(np.nonzero(binary_matrix[i,:])[0]))\n",
    "print(idf_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-public",
   "metadata": {},
   "source": [
    "# tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scheduled-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28178188 1.5655855  1.519828   ... 2.519828   2.519828   2.519828  ]\n"
     ]
    }
   ],
   "source": [
    "# Build first the Tf Matrix\n",
    "tf_matrix = np.zeros((len(dictionary),len(doc_corpus)), dtype = np.float32)\n",
    "# Doc corpus loop\n",
    "for doc_id, doc in enumerate(doc_corpus):\n",
    "    # Compute tf for each doc\n",
    "    for term in doc:\n",
    "        tf_matrix[term[0],doc_id] = np.log10(1+term[1])        \n",
    "# Build the idf array\n",
    "N = len(doc_corpus)\n",
    "idf_array1 = np.zeros((len(dictionary),), dtype = np.float32)\n",
    "# Compute the idf for each term\n",
    "for i, term in enumerate(tf_matrix):\n",
    "    idf_array1[i] = np.log10(N/len(np.nonzero(term)[0]))\n",
    "print(idf_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indie-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(idf_array)):\n",
    "    if idf_array1[i] != idf_array[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-delaware",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caring-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dq_to_vec(d_q):\n",
    "    \"\"\" Function to vectorize doc or query recieved\n",
    "    \n",
    "    Args:\n",
    "        d_q (list): Document or query to be vectorized\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Vector corresponding to the document\n",
    "    \n",
    "    \"\"\"\n",
    "    vec = np.zeros((len(dictionary), 1), dtype = np.float32)\n",
    "    for term in d_q:\n",
    "        vec[term[0]] = np.log10(1 + term[1]) * idf_array[term[0]]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "physical-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(doc,query):\n",
    "    \"\"\" Function to return the cosine similarity between to vectors\n",
    "    \n",
    "    Args:\n",
    "        doc (list): Document to be compared to query\n",
    "        query (list): Given query to find related documents.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.float32: Cosine similarity between query and document\n",
    "    \n",
    "    \"\"\"\n",
    "    doc = dq_to_vec(doc)\n",
    "    query = dq_to_vec(query)\n",
    "    return (sum(doc*query)/(np.sqrt(sum(doc**2))*np.sqrt(sum(query**2))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mighty-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_retrieval(query):\n",
    "    \"\"\" Function to return relevant documents to a query\n",
    "    \n",
    "    Args:\n",
    "        query (list): query to find related documents to.\n",
    "    \n",
    "    Returns:\n",
    "        list: Relevant documents\n",
    "    \n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for doc in doc_corpus:\n",
    "        scores.append(cosine_similarity(doc, query))\n",
    "    scores_sorted = scores.copy()\n",
    "    scores_sorted.sort(reverse = True)\n",
    "    docs = []\n",
    "    for score in scores_sorted[:len(np.nonzero(scores_sorted)[0])]:\n",
    "        docs.append(scores.index(score) + 1)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-entry",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "played-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Runs ranked retrieval and document vectorizarion for each query\n",
    "\n",
    "Args:\n",
    "    query_corpus (gensim.corpora.mmcorpus.MmCorpus): corpus with the queries. \n",
    "    df (pandas.core.frame.DataFrame): Dataframe with read queries.\n",
    "    \n",
    "Returns:\n",
    "    df (pandas.core.frame.DataFrame): Dataframe with new column with resulting documents for each query.\n",
    "\"\"\"\n",
    "\n",
    "df_results = []\n",
    "for query in query_corpus:\n",
    "    result_list = ''\n",
    "    results = ranked_retrieval(query)\n",
    "    for result in results:\n",
    "        result_list = result_list + 'd' + str(f'{result:03}') + ','\n",
    "    df_results.append(result_list[:-1])\n",
    "df['results'] = df_results\n",
    "df = df.set_index('query')\n",
    "# drop column and export tsv file with results\n",
    "df.drop('doc', axis=1).to_csv('./results/RRDV-queries_results.tsv', sep='\\t', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

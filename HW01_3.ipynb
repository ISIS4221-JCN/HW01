{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 Binary Search using Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('resources/vocab.dict')\n",
    "doc_corpus = corpora.MmCorpus('resources/doc_corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPIMI-like starts here\n",
    "\n",
    "# Creates a dictionary. Dictionary will hold token as key and list as value.\n",
    "index_dictionary = {}\n",
    "\n",
    "# Iterates over every document in the corpus\n",
    "for doc_indx in range(len(doc_corpus)):    \n",
    "    \n",
    "    # Retrieves document from corpus using index\n",
    "    document = doc_corpus[doc_indx]\n",
    "    \n",
    "    # Calculates document ID using the document index\n",
    "    doc_id = doc_indx + 1\n",
    "    \n",
    "    # Iterates over every token present in document\n",
    "    for token_indx in range(len(document)):\n",
    "        \n",
    "        # Converts token ID to token\n",
    "        token = document[token_indx][0]\n",
    "        \n",
    "        if token not in index_dictionary.keys():\n",
    "            index_dictionary[token] = [doc_id]\n",
    "        else:\n",
    "            index_dictionary[token].append(doc_id)\n",
    "            \n",
    "# Creates the numpy array\n",
    "inverted_index = np.zeros((len(dictionary), len(doc_corpus) + 1), dtype=np.int_)\n",
    "            \n",
    "# Calculates the relative frequency and converts to numpy array\n",
    "for key in index_dictionary.keys():\n",
    "    \n",
    "    relative_frequency = len(index_dictionary[key])\n",
    "    \n",
    "    inverted_index[key, 0] = relative_frequency\n",
    "    \n",
    "    inverted_index[key, 1:1+relative_frequency] = index_dictionary[key]\n",
    "\n",
    "# Saves the inverted index matrix\n",
    "np.save('./data/IImatrix.npy', inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = np.load('./data/IImatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(posting_list_0, posting_list_1, operator, n_docs, mod_term_0=False, mod_term_1=False):\n",
    "    \n",
    "    # Checks operator\n",
    "    if operator not in [\"OR\", \"AND\"]:\n",
    "        raise Exception(\"Not valid boolean operator. Operator must be either 'OR' or 'AND'.\")\n",
    "        \n",
    "    # Changes first posting lists if modifier is enabled\n",
    "    if mod_term_0:\n",
    "        posting_list_0 = [val for val in range(1, n_docs) if val not in posting_list_0]\n",
    "    \n",
    "    # Changes second posting lists if modifier is enabled\n",
    "    if mod_term_1:\n",
    "        posting_list_1 = [val for val in range(1, n_docs) if val not in posting_list_1]\n",
    "          \n",
    "    # Sets pl0 as the shortest and pl1 as the longest\n",
    "    if len(posting_list_1) < len(posting_list_0):\n",
    "        pl0, pl1 = posting_list_1, posting_list_0\n",
    "    else:\n",
    "        pl0, pl1 = posting_list_0, posting_list_1\n",
    "        \n",
    "    # Calculates the length of both lists\n",
    "    len_pl0 = len(pl0)\n",
    "    len_pl1 = len(pl1)\n",
    "    \n",
    "    # Creates the output list for merged posting lists  \n",
    "    merged = []\n",
    "        \n",
    "    # Creates index list\n",
    "    indexes = [0, 0]\n",
    "    \n",
    "    if operator == \"AND\" and (len(pl0) == 0 or len(pl1) == 0):\n",
    "        return []\n",
    "    else:\n",
    "        finish = False\n",
    "    \n",
    "    while not finish:\n",
    "        \n",
    "        # Retrieves postings from lists\n",
    "        posting0 = pl0[indexes[0]]\n",
    "        posting1 = pl1[indexes[1]]\n",
    "    \n",
    "        # If merging using an AND operator\n",
    "        if operator == \"AND\":\n",
    "            \n",
    "            if posting0 == posting1:\n",
    "                merged.append(posting0)\n",
    "            \n",
    "            if posting0 < posting1:\n",
    "                indexes[0] += 1\n",
    "            else:\n",
    "                indexes[1] += 1\n",
    "                \n",
    "            if indexes[0] == len_pl0 - 1 or indexes[1] == len_pl1 - 1:\n",
    "                finish = True\n",
    "        \n",
    "        # If merging using an OR operator\n",
    "        else:\n",
    "            \n",
    "            if indexes[0] != len_pl0 - 1:\n",
    "                \n",
    "                if posting0 < posting1:\n",
    "                    merged.append(posting0)\n",
    "                    indexes[0] += 1\n",
    "                    \n",
    "                elif posting0 == posting1:\n",
    "                    merged.append(posting0)\n",
    "                    indexes[0] += 1\n",
    "                    indexes[1] += 1\n",
    "                \n",
    "                else:\n",
    "                    merged.append(posting1)\n",
    "                    indexes[1] += 1\n",
    "                \n",
    "            else:\n",
    "                merged.append(posting1)\n",
    "                indexes[1] += 1\n",
    "                \n",
    "            if indexes[1] == len_pl1:\n",
    "                finish = True\n",
    "\n",
    "    # Returns output list for merge operation\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index_query(inverted_index, query, n_docs, conjunctive=True):\n",
    "    \n",
    "    # Array to store terms with relative frequency\n",
    "    terms = []\n",
    "    \n",
    "    # Sets the boolean operator\n",
    "    if conjunctive:\n",
    "        operator = \"AND\"\n",
    "    else:\n",
    "        operator = \"OR\"\n",
    "    \n",
    "    # Retrieves relative frequency from \n",
    "    for term in query:\n",
    "        rf = inverted_index[term][0]\n",
    "        terms.append([term, rf])\n",
    "    \n",
    "    # Converts to numpy array\n",
    "    terms = np.asarray(terms)\n",
    "    \n",
    "    # Orders the terms\n",
    "    terms = terms[terms[:, 1].argsort()]\n",
    "    \n",
    "    # Gets the first posting list\n",
    "    result = inverted_index[terms[0,0]][1::]\n",
    "    \n",
    "    # If there is more than one term, results are calculated\n",
    "    if terms.shape[0] != 1:\n",
    "        \n",
    "        # Removes zeroes from first posting list\n",
    "        result = result[result != 0]\n",
    "        \n",
    "        # Iterates over remaining posting lists\n",
    "        for indx in range(1, terms.shape[0]):\n",
    "            \n",
    "            # Gets second posting list\n",
    "            second = inverted_index[terms[indx, 0]][1::]\n",
    "            \n",
    "            # Removes zeroes from second posting list\n",
    "            second = second[second != 0]\n",
    "\n",
    "            result = merge(result, second, operator, 331)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    # If only one term is present in query, its posting list is returned\n",
    "    else:\n",
    "        return result[result != 0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'query_corpus.mm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4de583fc69b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reads query corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMmCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query_corpus.mm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Sets the query names from golden file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquery_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/relevance-judgments.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas-rocha/.local/lib/python3.6/site-packages/gensim/corpora/mmcorpus.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# avoid calling super(), too confusing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mIndexedCorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMmReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas-rocha/.local/lib/python3.6/site-packages/gensim/corpora/_mmreader.pyx\u001b[0m in \u001b[0;36mgensim.corpora._mmreader.MmReader.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas-rocha/.local/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_or_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas-rocha/.local/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mfile_or_filename\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# input was a filename: open as file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# input already a file-like object; just reset to the beginning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas-rocha/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nicolas-rocha/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'query_corpus.mm'"
     ]
    }
   ],
   "source": [
    "# Reads query corpus\n",
    "query_corpus = [[term[0] for term in query] for query in corpora.MmCorpus(\"./resources/query_corpus.mm\")]\n",
    "\n",
    "# Sets the query names from golden file\n",
    "query_names = list(pd.read_csv(\"./data/relevance-judgments.tsv\", sep='\\t', names=['query', 'd']).loc[:, \"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjuctive queries\n",
    "conj_file = open(\"./results/BSII-AND-queries-results.tsv\", \"w\")\n",
    "\n",
    "for query_indx in range(len(query_corpus)):\n",
    "    \n",
    "    name = query_names[query_indx]\n",
    "    \n",
    "    query = query_corpus[query_indx]\n",
    "    \n",
    "    result = inverted_index_query(inverted_index, query, 331, True)\n",
    "    \n",
    "    conj_file.write(name + '\\t')\n",
    "    \n",
    "    for r in result:\n",
    "        \n",
    "        conj_file.write('d' + str(r))\n",
    "        \n",
    "        if r != result[-1]:\n",
    "            conj_file.write(',')\n",
    "\n",
    "    conj_file.write('\\n')\n",
    "    \n",
    "conj_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disjunctive queries\n",
    "conj_file = open(\"./results/BSII-OR-queries-results.tsv\", \"w\")\n",
    "\n",
    "for query_indx in range(len(query_corpus)):\n",
    "    \n",
    "    name = query_names[query_indx]\n",
    "    \n",
    "    query = query_corpus[query_indx]\n",
    "    \n",
    "    result = inverted_index_query(inverted_index, query, 331, False)\n",
    "    \n",
    "    conj_file.write(name + '\\t')\n",
    "    \n",
    "    for r in result:\n",
    "        \n",
    "        conj_file.write('d' + str(r))\n",
    "        \n",
    "        if r != result[-1]:\n",
    "            conj_file.write(',')\n",
    "\n",
    "    conj_file.write('\\n')\n",
    "    \n",
    "conj_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 Binary Search using Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required libraries to execute the notebook\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the dictionary and document corpus from a preprocessed file\n",
    "dictionary = corpora.Dictionary.load('resources/vocab.dict')\n",
    "doc_corpus = corpora.MmCorpus('resources/doc_corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generates the inverted index from the document corpus.\n",
    "\n",
    "Args:\n",
    "    doc_corpus (gensim.corpora.mmcorpus.MmCorpus): document corpus used to generate the inverted index.\n",
    "    \n",
    "Returns:\n",
    "    inverted_matrix (numpy.ndarray): inverted index matrix with terms as the row index, \n",
    "        first column with the relative frequency and posting lists. The matrix is saved\n",
    "        on disk when completely generated.\n",
    "\"\"\"\n",
    "\n",
    "# Creates a dictionary. Dictionary will hold token as key and list as value.\n",
    "index_dictionary = {}\n",
    "\n",
    "# Iterates over every document in the corpus\n",
    "for doc_indx in range(len(doc_corpus)):    \n",
    "    \n",
    "    # Retrieves document from corpus using index\n",
    "    document = doc_corpus[doc_indx]\n",
    "    \n",
    "    # Calculates document ID using the document index\n",
    "    doc_id = doc_indx + 1\n",
    "    \n",
    "    # Iterates over every token present in document\n",
    "    for token_indx in range(len(document)):\n",
    "        \n",
    "        # Converts token ID to token\n",
    "        token = document[token_indx][0]\n",
    "        \n",
    "        if token not in index_dictionary.keys():\n",
    "            index_dictionary[token] = [doc_id]\n",
    "        else:\n",
    "            index_dictionary[token].append(doc_id)\n",
    "            \n",
    "# Creates the numpy array\n",
    "inverted_index = np.zeros((len(dictionary), len(doc_corpus) + 1), dtype=np.int_)\n",
    "            \n",
    "# Calculates the relative frequency and converts to numpy array\n",
    "for key in index_dictionary.keys():\n",
    "    \n",
    "    relative_frequency = len(index_dictionary[key])\n",
    "    \n",
    "    inverted_index[key, 0] = relative_frequency\n",
    "    \n",
    "    inverted_index[key, 1:1+relative_frequency] = index_dictionary[key]\n",
    "\n",
    "# Saves the inverted index matrix\n",
    "np.save('./data/IImatrix.npy', inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the inverted index from disk\n",
    "inverted_index = np.load('./data/IImatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(posting_list_0, posting_list_1, operator, n_docs, mod_term_0=False, mod_term_1=False):\n",
    "    \"\"\" Merges two posting lists supporting a binary operator and modifiers.\n",
    "    \n",
    "    Args:\n",
    "        posting_list_0 (list): list with the postings for the first term.\n",
    "        posting_list_1 (list): list with the postings for the second term.\n",
    "        operator (str): binary operator used to merge the lists. It could be\n",
    "            either 'AND' or 'NOT'.\n",
    "        n_docs (int): total number of documents in the corpus.\n",
    "        mod_term_0 (bool): boolean modifier for the first posting list. If set to\n",
    "            False, no modifying action is done. Otherwise, a NOT operator is used \n",
    "            for the posting lists.\n",
    "        mod_term_0 (bool): boolean modifier for the second posting list. If set to\n",
    "            False, no modifying action is done. Otherwise, a NOT operator is used \n",
    "            for the posting lists.\n",
    "    \n",
    "    Returns:\n",
    "        list: merged posting lists.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: if the boolean operator is not valid.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Checks operator\n",
    "    if operator not in [\"OR\", \"AND\"]:\n",
    "        raise Exception(\"Not valid boolean operator. Operator must be either 'OR' or 'AND'.\")\n",
    "        \n",
    "    # Changes first posting lists if modifier is enabled\n",
    "    if mod_term_0:\n",
    "        posting_list_0 = [val for val in range(1, n_docs) if val not in posting_list_0]\n",
    "    \n",
    "    # Changes second posting lists if modifier is enabled\n",
    "    if mod_term_1:\n",
    "        posting_list_1 = [val for val in range(1, n_docs) if val not in posting_list_1]\n",
    "          \n",
    "    # Sets pl0 as the shortest and pl1 as the longest\n",
    "    if len(posting_list_1) < len(posting_list_0):\n",
    "        pl0, pl1 = posting_list_1, posting_list_0\n",
    "    else:\n",
    "        pl0, pl1 = posting_list_0, posting_list_1\n",
    "        \n",
    "    # Calculates the length of both lists\n",
    "    len_pl0 = len(pl0)\n",
    "    len_pl1 = len(pl1)\n",
    "    \n",
    "    # Creates the output list for merged posting lists  \n",
    "    merged = []\n",
    "        \n",
    "    # Creates index list\n",
    "    indexes = [0, 0]\n",
    "    \n",
    "    # Creates a stop condition for a disjunctive merge with an empty list\n",
    "    if operator == \"AND\" and (len(pl0) == 0 or len(pl1) == 0):\n",
    "        return []\n",
    "    else:\n",
    "        finish = False\n",
    "    \n",
    "    # Main merging loop\n",
    "    while not finish:\n",
    "        \n",
    "        # Retrieves postings from lists\n",
    "        posting0 = pl0[indexes[0]]\n",
    "        posting1 = pl1[indexes[1]]\n",
    "    \n",
    "        # If merging using an AND operator\n",
    "        if operator == \"AND\":\n",
    "            \n",
    "            # Adds posting to merged list\n",
    "            if posting0 == posting1:\n",
    "                merged.append(posting0)\n",
    "            \n",
    "            # Increments corresponding pointer\n",
    "            if posting0 < posting1:\n",
    "                indexes[0] += 1\n",
    "            else:\n",
    "                indexes[1] += 1\n",
    "                \n",
    "            # Verifies stop condition\n",
    "            if indexes[0] == len_pl0 - 1 or indexes[1] == len_pl1 - 1:\n",
    "                finish = True\n",
    "        \n",
    "        # If merging using an OR operator\n",
    "        else:\n",
    "            \n",
    "            # Moves along first list\n",
    "            if indexes[0] != len_pl0 - 1:\n",
    "                \n",
    "                # Checks condition for smaller list\n",
    "                if posting0 < posting1:\n",
    "                    merged.append(posting0)\n",
    "                    indexes[0] += 1\n",
    "                    \n",
    "                # Checks condition for both lists\n",
    "                elif posting0 == posting1:\n",
    "                    merged.append(posting0)\n",
    "                    indexes[0] += 1\n",
    "                    indexes[1] += 1\n",
    "                \n",
    "                # Checks condition for longer list\n",
    "                else:\n",
    "                    merged.append(posting1)\n",
    "                    indexes[1] += 1\n",
    "                \n",
    "            # Moves along second list\n",
    "            else:\n",
    "                merged.append(posting1)\n",
    "                indexes[1] += 1\n",
    "            \n",
    "            # Checks stop condition\n",
    "            if indexes[1] == len_pl1:\n",
    "                finish = True\n",
    "\n",
    "    # Returns output list for merge operation\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index_query(inverted_index, query, n_docs, conjunctive=True):\n",
    "    \"\"\" Executes a query for the inverted index.\n",
    "    \n",
    "    Args:\n",
    "        inverted_index (numpy.ndarray): matrix with the inverted index. Assumed to have the row index as\n",
    "            the term, the first column as the relative frequency and the remainder as the posting lists.\n",
    "        query (list): list with the terms included in the query.\n",
    "        n_docs (int): total number of documents in corpus.\n",
    "        conjunctive (bool): performs the query in a conjunctive way if True, disjunct otherwise.\n",
    "        \n",
    "    Returns:\n",
    "        list: with the query relevant documents.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Array to store terms with relative frequency\n",
    "    terms = []\n",
    "    \n",
    "    # Sets the boolean operator\n",
    "    if conjunctive:\n",
    "        operator = \"AND\"\n",
    "    else:\n",
    "        operator = \"OR\"\n",
    "    \n",
    "    # Retrieves relative frequency from \n",
    "    for term in query:\n",
    "        rf = inverted_index[term][0]\n",
    "        terms.append([term, rf])\n",
    "    \n",
    "    # Converts to numpy array\n",
    "    terms = np.asarray(terms)\n",
    "    \n",
    "    # Orders the terms\n",
    "    terms = terms[terms[:, 1].argsort()]\n",
    "    \n",
    "    # Gets the first posting list\n",
    "    result = inverted_index[terms[0,0]][1::]\n",
    "    \n",
    "    # If there is more than one term, results are calculated\n",
    "    if terms.shape[0] != 1:\n",
    "        \n",
    "        # Removes zeroes from first posting list\n",
    "        result = result[result != 0]\n",
    "        \n",
    "        # Iterates over remaining posting lists\n",
    "        for indx in range(1, terms.shape[0]):\n",
    "            \n",
    "            # Gets second posting list\n",
    "            second = inverted_index[terms[indx, 0]][1::]\n",
    "            \n",
    "            # Removes zeroes from second posting list\n",
    "            second = second[second != 0]\n",
    "\n",
    "            # Merges the posting lists\n",
    "            result = merge(result, second, operator, n_docs)\n",
    "            \n",
    "        # Returns the result for the lists\n",
    "        return result\n",
    "    \n",
    "    # If only one term is present in query, its posting list is returned\n",
    "    else:\n",
    "        return result[result != 0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads query corpus\n",
    "query_corpus = [[term[0] for term in query] for query in corpora.MmCorpus(\"./resources/query_corpus.mm\")]\n",
    "\n",
    "# Sets the query names from golden file\n",
    "query_names = list(pd.read_csv(\"./data/relevance-judgments.tsv\", sep='\\t', names=['query', 'd']).loc[:, \"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 0.0015923261642456054 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Executes the conjunctive queries and writes the results into a file.\n",
    "\n",
    "Args:\n",
    "    query_corpus (list): has lists whose elements are the terms used in the query.\n",
    "    query_names (list): contains the names of the queries.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Sets a variable with the number of iterations to average\n",
    "N = 10\n",
    "\n",
    "# Initializes time value\n",
    "cumulative_time = 0\n",
    "\n",
    "# Runs the queries for a given time\n",
    "for iteration in range(N):\n",
    "    \n",
    "    # Sets initial time\n",
    "    initial_time = time.time()\n",
    "    \n",
    "    # Opens the results file\n",
    "    conj_file = open(\"./results/BSII-AND-queries-results.tsv\", \"w\")\n",
    "\n",
    "    # Iterates over queries\n",
    "    for query_indx in range(len(query_corpus)):\n",
    "\n",
    "        # Gets the query name from the corresponding list\n",
    "        name = query_names[query_indx]\n",
    "\n",
    "        # Gets the query terms from the corresponding list\n",
    "        query = query_corpus[query_indx]\n",
    "\n",
    "        # Executes the query in the inverted index\n",
    "        result = inverted_index_query(inverted_index, query, 331, True)\n",
    "\n",
    "        # Writes the name into the file\n",
    "        conj_file.write(name + '\\t')\n",
    "\n",
    "        # Writes relevant documents' ID into the file\n",
    "        for r in result:\n",
    "            conj_file.write('d' + str(r))\n",
    "\n",
    "            # Condition to write or not a comma\n",
    "            if r != result[-1]:\n",
    "                conj_file.write(',')\n",
    "\n",
    "        # Writes a new line\n",
    "        conj_file.write('\\n')\n",
    "        \n",
    "    # Calculates final time\n",
    "    cumulative_time += time.time() - initial_time\n",
    "\n",
    "    # Closes the file\n",
    "    conj_file.close()\n",
    "    \n",
    "print(\"Average time: {} s\".format(cumulative_time / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 1.7182111740112305 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Executes the disjuct queries and writes the results into a file.\n",
    "\n",
    "Args:\n",
    "    query_corpus (list): has lists whose elements are the terms used in the query.\n",
    "    query_names (list): contains the names of the queries.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Sets a variable with the number of iterations to average\n",
    "N = 10\n",
    "\n",
    "# Initializes time value\n",
    "cumulative_time = 0\n",
    "\n",
    "# Runs the queries for a given time\n",
    "for iteration in range(N):\n",
    "\n",
    "    # Sets initial time\n",
    "    initial_time = time.time()\n",
    "\n",
    "    # Opens the results file\n",
    "    conj_file = open(\"./results/BSII-OR-queries-results.tsv\", \"w\")\n",
    "\n",
    "    for query_indx in range(len(query_corpus)):\n",
    "        \n",
    "\n",
    "        # Gets the query name from the corresponding list\n",
    "        name = query_names[query_indx]\n",
    "\n",
    "        # Gets the query terms from the corresponding list\n",
    "        query = query_corpus[query_indx]\n",
    "\n",
    "        # Executes the query in the inverted index\n",
    "        result = inverted_index_query(inverted_index, query, 331, False)\n",
    "\n",
    "        # Writes the name into the file\n",
    "        conj_file.write(name + '\\t')\n",
    "\n",
    "        # Writes relevant documents' ID into the file\n",
    "        for r in result:\n",
    "            conj_file.write('d' + str(r))\n",
    "\n",
    "            # Condition to write or not a comma\n",
    "            if r != result[-1]:\n",
    "                conj_file.write(',')\n",
    "\n",
    "        # Writes a new line\n",
    "        conj_file.write('\\n')\n",
    "        \n",
    "    # Calculates final time\n",
    "    cumulative_time += time.time() - initial_time\n",
    "\n",
    "    # Closes the file\n",
    "    conj_file.close()\n",
    "\n",
    "print(\"Average time: {} s\".format(cumulative_time / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
